{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679bf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# find indices of grid cell containing x, y\n",
    "def get_nearest_xy(x, y, x_array, y_array):\n",
    "   \"\"\"\n",
    "     search for nearest grid cell in an array of grid cells and return the index.\n",
    "     np.argmin returns the indices of minium value along an axis.\n",
    "     so subtract dd from all values in dd_array, take absolute value and find index of minium.\n",
    "    \"\"\"\n",
    "   x_idx = (np.abs(x_array - x)).argmin()\n",
    "   y_idx = (np.abs(y_array - y)).argmin()\n",
    "   return x_idx, y_idx\n",
    "\n",
    "my_home_dir_name = 'my_home_dir'\n",
    "my_personal_bucket_name = 'my_bucket'\n",
    "my_cmip6_bucket_name = 'cmip6_data'\n",
    "\n",
    "loc = 'Addis Ababa'\n",
    "lats_lons = [(9.25, 38.75)]\n",
    "\n",
    "ssp = 'ssp245'\n",
    "variable = 'tasmax'\n",
    "variable_long = 'maximum_temperature'\n",
    "units = 'C'\n",
    "days_since = dt.datetime(1850, 1, 1)  # specific to time in nc file\n",
    "\n",
    "season = 'annual'\n",
    "months2include = {  # comment out undesired months\n",
    "   'January': 1,\n",
    "    'February': 2,\n",
    "    'March': 3,\n",
    "    'April': 4,\n",
    "    'May': 5,\n",
    "    'June':6,\n",
    "    'July': 7,\n",
    "    'August': 8,\n",
    "    'September': 9,\n",
    "    'October': 10,\n",
    "    'November': 11,\n",
    "    'December': 12\n",
    "}\n",
    "\n",
    "percentile = 0.5  # decimal\n",
    "percentile_2 = 0.95  # optional 2nd percentile line, set to 0 otherwise\n",
    "\n",
    "data_path = f'/home/{my_home_dir_name}/{my_cmip6_bucket_name}/ISIMIP_BASD_data/daily/{variable_long}/{ssp}'\n",
    "save_path = f'/home/{my_home_dir_name}/{my_personal_bucket_name}/{loc}/distplot'\n",
    "\n",
    "# read in model names from modelNames.txt\n",
    "with open(f'/home/{my_home_dir_name}/modelNames.txt') as f:\n",
    "    models = [line.strip() for line in f]\n",
    "\n",
    "yrs_base = np.arange(2000, 2020 + 1)\n",
    "yrs_fut = np.arange(2040, 2060 + 1)\n",
    "yrs_fut2 = []  # np.arange(2070, 2090 + 1)\n",
    "\n",
    "base_list = np.array([])\n",
    "fut_list = np.array([])\n",
    "fut2_list = np.array([])\n",
    "\n",
    "# assemble df column names based on desired years\n",
    "col1 = 'location'\n",
    "col2 = '%s-%s' % (yrs_base[0], yrs_base[-1])\n",
    "col3 = '%s-%s' % (yrs_fut[0], yrs_fut[-1])\n",
    "\n",
    "if len(yrs_fut2) > 0:\n",
    "    col4 = '%s-%s' % (yrs_fut2[0], yrs_fut2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e1addd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open single file to get correct lat/lon indices\n",
    "file = Dataset(f'{data_path}/{variable}_{models[0]}_{ssp}_basd_0.5deg_{yrs_base[0]}.nc', 'r')\n",
    "\n",
    "lons_input = file.variables['lon'][:]\n",
    "lats_input = file.variables['lat'][:]\n",
    "\n",
    "lats_lons_idc = []\n",
    "for lat, lon in lats_lons:\n",
    "    lon_idx, lat_idx = get_nearest_xy(lon, lat, lons_input, lats_input)\n",
    "    lats_lons_idc.append((lat_idx, lon_idx))\n",
    "    \n",
    "for lat, lon in lats_lons_idc:\n",
    "    print(lats_input[lat], lons_input[lon])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11042e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data and build df based on years\n",
    "df1 = pd.DataFrame(columns=[col1, col2])\n",
    "df2 = pd.DataFrame(columns=[col1, col3])\n",
    "\n",
    "if len(yrs_fut2) > 0:\n",
    "    df3 = pd.DataFrame(columns=[col1, col4])\n",
    "\n",
    "for year in np.arange(1971, 2100 + 1):\n",
    "    for m in models:\n",
    "        if year in yrs_base or year in yrs_fut or year in yrs_fut2:\n",
    "            print(year, m)                \n",
    "            file = Dataset(f'{data_path}/{variable}_{m}_{ssp}_basd_0.5deg_{year}.nc', 'r')\n",
    "            time = pd.DataFrame([(days_since + dt.timedelta(i)) for i in list(file.variables['time'][:])])\n",
    "            months_idc = time.index[time[0].dt.month.isin(list(months2include.values()))]\n",
    "\n",
    "            # drop last index if leap year and February in months2include for easier merging of dfs\n",
    "            if 'February' in months2include.keys() and ((year % 400 == 0) or (year % 4 == 0 and year % 100 != 0)):\n",
    "                months_idc = months_idc[0:-1]\n",
    "            \n",
    "            for lat_lon in lats_lons_idc:\n",
    "                data = file.variables[variable][months_idc, lat_lon[0], lat_lon[1]]\n",
    "\n",
    "                df_loc = pd.DataFrame(columns=[col1])\n",
    "                \n",
    "                if year in yrs_base:\n",
    "                    df_loc[col2] = data\n",
    "                    df_loc[col1] = loc\n",
    "                    df1 = pd.concat([df1, df_loc])\n",
    "                elif year in yrs_fut:\n",
    "                    df_loc[col3] = data\n",
    "                    df_loc[col1] = loc\n",
    "                    df2 = pd.concat([df2, df_loc])\n",
    "                elif year in yrs_fut2:\n",
    "                    df_loc[col4] = data\n",
    "                    df_loc[col1] = loc\n",
    "                    df3 = pd.concat([df3, df_loc])\n",
    "                               \n",
    "            file.close()\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "df = df1.combine_first(df2)\n",
    "\n",
    "if len(yrs_fut2) > 0:\n",
    "    df = df.combine_first(df3)\n",
    "\n",
    "df.reset_index(drop=True)\n",
    "\n",
    "location = df[col1]  # 'combine_first' moved location to end. This sequence brings it back to the first column\n",
    "df = df.drop(columns=col1)\n",
    "df.insert(loc=0, column=col1, value=location)\n",
    "\n",
    "# save data\n",
    "df.to_csv(f'{save_path}/{loc.replace(\" \", \"_\")}_{variable}_distribution_data_{ssp}_{season}.csv', index=False)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c7691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv(f'{save_path}/{loc.replace(\" \", \"_\")}_{variable}_distribution_data_{ssp}_{season}.csv', header=0)\n",
    "\n",
    "df.iloc[:, 1:] = df.iloc[:, 1:] - 273.15  # K to C\n",
    "\n",
    "if units == 'F':\n",
    "    df.iloc[:, 1:] = df.iloc[:, 1:] * 1.8 + 32  # C to F\n",
    "    \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc9d330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.lines import Line2D\n",
    "plt.rcParams['font.family'] = ['Arial']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "\n",
    "# adjust these as needed for pretty plot\n",
    "percentile_text_horz_offset, percentile_text_vert_offset = 1.5, 0.01  # adjusts Nth percentile text up and down\n",
    "percentile2_text_horz_offset, percentile2_text_vert_offset = 0.9, 0.03  # adjusts (optional) 2nd Nth percentile text up and down\n",
    "arrow_style = 'arc3,rad=0.1'  # adjusts curve of arrow associated with Nth percentile text\n",
    "arrow2_style = 'arc3,rad=0.3'  # adjusts curve of arrow associated with (optional) 2nd Nth percentile text\n",
    "legend_horz_adjust, legend_vert_adjust = 0.22, 0.92  # adjusts legend box from ll corner\n",
    "plot_suptitle = False  # set to True to add '{loc} Daily Maximum Temperatures' title at top of plot, otherwise set to False\n",
    "subplot_label = '(c)'  # (a), (b), (1), (2) etc. (use when making multiple plots for reports), set to '' if only one plot\n",
    "label_horz_adjust, label_vert_adjust = 0.1, 0.004  # adjusts location of plot label text\n",
    "plot_ssp = True  # adds ssp text to plot when set to True, otherwise set to False\n",
    "ssp_horz_adjust, ssp_vert_adjust = label_horz_adjust + 0.18, label_vert_adjust + 0.13  # adjusts location of plot ssp text\n",
    "ax.set_ylim((0, 0.2))  # adjust height of plot by altering second value - or comment out for default height near top of curve\n",
    "\n",
    "# get Nth percentile values\n",
    "percentiles = df.quantile(q=percentile, axis=0, numeric_only=True, interpolation='linear')\n",
    "percentiles = np.round_(percentiles, decimals=1)\n",
    "height_of_fut_perc_line = []\n",
    "\n",
    "if percentile_2 != 0:\n",
    "    percentiles_2 = df.quantile(q=percentile_2, axis=0, numeric_only=True, interpolation='linear')\n",
    "    percentiles_2 = np.round_(percentiles_2, decimals=1)\n",
    "    height_of_fut_perc2_line = []\n",
    "    \n",
    "fontsize = 20\n",
    "\n",
    "if len(yrs_fut2) > 0:\n",
    "    colors = ['#52bbaf', '#e9c46a', '#ebad7b']\n",
    "else:\n",
    "    colors = ['#52bbaf', '#ebad7b']    \n",
    "   \n",
    "# round xticks to nearest N, using min/max values of data as guiding limits\n",
    "round_to = 5\n",
    "xtick_min, xtick_max = np.around(np.min(df)[1] / round_to, decimals=0) * round_to, np.around(np.max(df)[-1] / round_to, decimals=0) * round_to\n",
    "\n",
    "for col_i in np.arange(0, len(df.columns) - 1):\n",
    "    dis = sns.kdeplot(df.iloc[:, col_i + 1], color=colors[col_i])\n",
    "    dis_x = dis.lines[col_i].get_xydata()[:, 0]\n",
    "    dis_y = dis.lines[col_i].get_xydata()[:, 1]\n",
    "    dis.fill_between(dis_x, dis_y, color=colors[col_i], alpha=0.5)\n",
    "\n",
    "    # find index where line is closest to percentile value\n",
    "    percentile_idx = (np.abs(percentiles[col_i] - dis_x)).argmin()\n",
    "    if percentile_2 != 0:\n",
    "        percentile2_idx = (np.abs(percentiles_2[col_i] - dis_x)).argmin()\n",
    "\n",
    "    if col_i == (len(df.columns) - 2): # save heights of last time period percentile line \n",
    "        height_of_fut_perc_line.append(dis_y[percentile_idx])\n",
    "        if percentile_2 != 0:\n",
    "            height_of_fut_perc2_line.append(dis_y[percentile2_idx])\n",
    "\n",
    "    # 95th percentile line\n",
    "    ax.vlines(x=percentiles[col_i], ymin=0, ymax=dis_y[percentile_idx], colors='k', ls='--', lw=1, alpha=0.5)\n",
    "    if percentile_2 != 0:\n",
    "        ax.vlines(x=percentiles_2[col_i], ymin=0, ymax=dis_y[percentile2_idx], colors='k', ls='--', lw=1, alpha=0.5)\n",
    "\n",
    "ax.annotate('%d$^{th}$ percentile increases\\nfrom %.1f to %.1f \\u00B0%s' % \\\n",
    "            (percentile*100, percentiles[0], percentiles[-1], units), \n",
    "            xy=(percentiles[-1], height_of_fut_perc_line[0]),\n",
    "            xytext=(percentiles[-1] + percentile_text_horz_offset, \n",
    "                    height_of_fut_perc_line[0] + percentile_text_vert_offset), \n",
    "            fontsize=fontsize-2, \n",
    "            arrowprops=dict(facecolor='black',\n",
    "                            shrink=0.1,\n",
    "                            alpha=0.3,\n",
    "                            width=2,\n",
    "                            connectionstyle=arrow_style))\n",
    "\n",
    "if percentile_2 != 0:\n",
    "    ax.annotate('%d$^{th}$ percentile increases\\nfrom %.1f to %.1f \\u00B0%s' % \\\n",
    "                (percentile_2*100, percentiles_2[0], percentiles_2[-1], units), \n",
    "                xy=(percentiles_2[-1], height_of_fut_perc2_line[0]),\n",
    "                xytext=(percentiles_2[-1] + percentile2_text_horz_offset, \n",
    "                        height_of_fut_perc2_line[0] + percentile2_text_vert_offset), \n",
    "                fontsize=fontsize-2, \n",
    "                arrowprops=dict(facecolor='black',\n",
    "                                shrink=0.1,\n",
    "                                alpha=0.3,\n",
    "                                width=2,\n",
    "                                connectionstyle=arrow2_style))\n",
    "\n",
    "ax.set_xlabel(f'Temperature (\\u00B0{units})', fontsize=fontsize + 4)\n",
    "#ax.set_xlabel('')\n",
    "ax.set_ylabel('')\n",
    "\n",
    "ax.set_xlim((xtick_min, xtick_max))\n",
    "plt.xticks(np.arange(xtick_min, xtick_max, round_to), fontsize=fontsize)\n",
    "ax.set_yticks([])\n",
    "\n",
    "# build legend manually\n",
    "legend_elements = []\n",
    "for i in np.arange(len(colors)):\n",
    "    legend_label = '%s\\u2013%s' % (df.columns[i + 1][:4], df.columns[i + 1][-4:])\n",
    "    legend_elements.append(Line2D([0], [0], color=colors[i], lw=2, label=legend_label))  \n",
    "\n",
    "if plot_suptitle == True:\n",
    "    plt.suptitle(f'{loc} Daily Maximum Temperatures', fontsize=fontsize+5, weight='bold')\n",
    "\n",
    "if len(months2include) == 12:\n",
    "    ax.set_title(f'{subplot_label} Annual', fontsize=fontsize+4, loc='left')  # , style='italic')\n",
    "else:\n",
    "    ax.set_title('{} {}, {}, {}'.format(subplot_label, *list(months2include.keys())), fontsize=fontsize+4, loc='left')  # , style='italic')\n",
    "    \n",
    "fig.legend(handles=legend_elements, bbox_to_anchor=(legend_horz_adjust, legend_vert_adjust), fontsize=fontsize+4) \n",
    "\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "fig.tight_layout()\n",
    "\n",
    "# add ssp\n",
    "if plot_ssp == True:\n",
    "    ax.annotate(ssp, xy=(xtick_min, 0), xytext=(xtick_min + ssp_horz_adjust, ssp_vert_adjust), fontsize=fontsize)  # , style='italic')\n",
    "\n",
    "if percentile_2 != 0:\n",
    "    plt.savefig(f'{save_path}/{loc.replace(\" \", \"_\")}_{variable}_distribution_plot_{ssp}_{season}_{round(percentile*100)}th_and_{round(percentile_2*100)}th_perc.png')\n",
    "else:\n",
    "    plt.savefig(f'{save_path}/{loc.replace(\" \", \"_\")}_{variable}_distribution_plot_{ssp}_{season}_{round(percentile*100)}th_perc.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
